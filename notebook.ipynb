{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a5d346",
   "metadata": {},
   "source": [
    "# Load Dataset Using ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2114f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader # `DataLoader` to load data in batches and enable shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df98fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((150,150)),  # Resize all images to 150x150 pixels\n",
    "    transforms.ToTensor()          # Convert PIL Image or numpy.ndarray to a PyTorch tensor\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3db9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset from the \"chest_xray/train\" directory and apply the transformations\n",
    "train_data=datasets.ImageFolder(\"chest_xray/train\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe0dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_data=datasets.ImageFolder(\"chest_xray/val\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d795335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset from the \"chest_xray/test\" directory and apply the transformations\n",
    "test_data = datasets.ImageFolder(\"chest_xray/test\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3ee713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training data\n",
    "# - batch_size=32: load 32 images at a time\n",
    "# - shuffle=True: shuffle the data at every epoch to improve generalization\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a933bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the validation data\n",
    "# - shuffle=False: do not shuffle, as it's not needed for evaluation\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b368dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the test data\n",
    "# - shuffle=False: keep the order of test data consistent for evaluation\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3db8fd",
   "metadata": {},
   "source": [
    "# Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e10b2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from PyTorch\n",
    "import torch.nn as nn                 # Contains building blocks like layers\n",
    "import torch.nn.functional as F      # Contains functions like ReLU, sigmoid, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01351c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model for pneumonia detection\n",
    "class PneumoniaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PneumoniaCNN,self).__init__()# Initialize the base class nn.Module\n",
    "        # First convolutional layer:\n",
    "        # - Input channels: 3 (RGB image)\n",
    "        # - Output channels: 32\n",
    "        # - Kernel size: 3x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "\n",
    "        # Max pooling layer with:\n",
    "        # - Kernel size: 2x2\n",
    "        # - Stride: 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second convolutional layer:\n",
    "        # - Input channels: 32\n",
    "        # - Output channels: 64\n",
    "        # - Kernel size: 3x3\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self._to_linear = 64 * 36 * 36\n",
    "\n",
    "        # Fully connected layer:\n",
    "        # - Input features: 64 * 35 * 35 (flattened feature map size after conv and pooling)\n",
    "        # - Output features: 128\n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "\n",
    "        # Dropout layer with 50% probability to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Output layer:\n",
    "        # - Input features: 128\n",
    "        # - Output features: 1 (binary classification: pneumonia or not)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolution, ReLU activation, and max pooling\n",
    "        # Output shape after conv1: (32, 148, 148) -> after pool: (32, 74, 74)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "         # Apply second convolution, ReLU activation, and max pooling\n",
    "        # Output shape after conv2: (64, 72, 72) -> after pool: (64, 35, 35)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "         # Flatten the tensor to feed into the fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "         # Apply ReLU activation to the first fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "         # Apply dropout to reduce overfitting\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output layer with sigmoid to get a probability (binary classification)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        # Return the final prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd056131",
   "metadata": {},
   "source": [
    "# Train the Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25259648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and the optimizer module\n",
    "import torch\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4d1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b141ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and move it to the selected device (GPU/CPU)\n",
    "model = PneumoniaCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f4d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function:\n",
    "# - BCELoss is used for binary classification problems (outputs between 0 and 1)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d0dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer:\n",
    "# - Adam optimizer with a learning rate of 0.001\n",
    "# - It will update the model's parameters during training\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f912e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4288\n",
      "Epoch 2, Loss: 0.2549\n",
      "Epoch 3, Loss: 0.2337\n",
      "Epoch 4, Loss: 0.1959\n",
      "Epoch 5, Loss: 0.1616\n"
     ]
    }
   ],
   "source": [
    "# Training loop for 5 epochs\n",
    "for epoch in range(5):\n",
    "    model.train()  # Set the model to training mode (enables dropout, batchnorm, etc.)\n",
    "    running_loss = 0.0  # To accumulate loss for the epoch\n",
    " \n",
    "    # Iterate over batches of images and labels from the training DataLoader\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the selected device\n",
    "        images = images.to(device)\n",
    "        # Convert labels to float and reshape to (batch_size, 1) to match model output\n",
    "        labels = labels.float().to(device).unsqueeze(1)\n",
    "\n",
    "        # Zero out gradients from the previous step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform a forward pass through the model\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute the binary cross-entropy loss between predictions and actual labels\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagate the loss to compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model's weights using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the current batch's loss to the running total\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0855c2",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7138d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.36      0.52       234\n",
      "   Pneumonia       0.72      0.99      0.83       390\n",
      "\n",
      "    accuracy                           0.75       624\n",
      "   macro avg       0.84      0.67      0.68       624\n",
      "weighted avg       0.81      0.75      0.72       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the classification_report function to generate a text summary of precision, recall, F1-score, etc.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the model to evaluation mode (important for models with dropout or batch norm)\n",
    "model.eval()\n",
    "\n",
    "# Initialize empty lists to store true labels and predicted labels\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "# Disable gradient calculation to save memory and computations during inference\n",
    "with torch.no_grad():\n",
    "    # Iterate over the test dataset in batches\n",
    "    for images, labels in test_loader:\n",
    "        # Move the images to the same device as the model (CPU or GPU)\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Get model outputs (logits or probabilities), move to CPU, and convert to NumPy array\n",
    "        outputs = model(images).cpu().numpy()\n",
    "\n",
    "        # Apply threshold to outputs to get binary predictions (1 if > 0.5 else 0), and flatten to 1D\n",
    "        preds = (outputs > 0.5).astype(int).flatten()\n",
    "\n",
    "        # Append predictions to the predicted labels list\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "        # Convert true labels to NumPy array and append to the true labels list\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "\n",
    "# Print a detailed classification report comparing true vs. predicted labels\n",
    "# Includes precision, recall, F1-score for each class (Normal and Pneumonia)\n",
    "print(classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f36f3763",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"pneumonia_cnn.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
